import os
from datetime import datetime
from dotenv import load_dotenv
from groq import Groq

# Load environment variables
load_dotenv()

class EnglishTutorAgent:
    def __init__(self):
        """Initialize the English Tutor Agent with Groq"""
        self.client = Groq(
            api_key=os.getenv('GROQ_API_KEY')
        )
        self.conversation_history = []
        self.user_profile = {
            'level': 'beginner',  # beginner, intermediate, advanced
            'focus_areas': ['grammar', 'vocabulary', 'conversation'],
            'native_language': 'vietnamese',
            'goals': 'general_english'
        }
        # C√°c model mi·ªÖn ph√≠ t·ªët tr√™n Groq
        self.available_models = {
            'fast': 'llama-3.1-8b-instant',      # Nhanh nh·∫•t, t·ªët cho h·ªôi tho·∫°i
            'balanced': 'llama3-70b-8192', 
            'smart': 'mixtral-8x7b-32768',       # Th√¥ng minh, context d√†i
            'coding': 'llama-3.2-90b-text-preview' # T·ªët nh·∫•t cho gi·∫£i th√≠ch
        }
        self.current_model = self.available_models['balanced']  # Model m·∫∑c ƒë·ªãnh
        
    def set_system_prompt(self):
        """Create system prompt based on user profile"""
        level_descriptions = {
            'beginner': 's·ª≠ d·ª•ng t·ª´ v·ª±ng ƒë∆°n gi·∫£n, ng·ªØ ph√°p c∆° b·∫£n',
            'intermediate': 's·ª≠ d·ª•ng c·∫•u tr√∫c c√¢u ph·ª©c t·∫°p h∆°n, t·ª´ v·ª±ng ƒëa d·∫°ng',
            'advanced': 'th·∫£o lu·∫≠n c√°c ch·ªß ƒë·ªÅ ph·ª©c t·∫°p, s·ª≠ d·ª•ng ng√¥n ng·ªØ tinh t·∫ø'
        }
        
        return f"""B·∫°n l√† m·ªôt gi√°o vi√™n ti·∫øng Anh AI th√¢n thi·ªán v√† ki√™n nh·∫´n. 

H·ªçc vi√™n c·ªßa b·∫°n:
- Tr√¨nh ƒë·ªô: {self.user_profile['level']} ({level_descriptions[self.user_profile['level']]})
- Ng√¥n ng·ªØ m·∫π ƒë·∫ª: Ti·∫øng Vi·ªát
- M·ª•c ti√™u: {self.user_profile['goals']}

Nhi·ªám v·ª• c·ªßa b·∫°n:
1. Tr√≤ chuy·ªán t·ª± nhi√™n b·∫±ng ti·∫øng Anh v·ªõi h·ªçc vi√™n
2. ƒêi·ªÅu ch·ªânh ƒë·ªô kh√≥ ph√π h·ª£p v·ªõi tr√¨nh ƒë·ªô
3. S·ª≠a l·ªói m·ªôt c√°ch nh·∫π nh√†ng v√† gi·∫£i th√≠ch r√µ r√†ng
4. Khuy·∫øn kh√≠ch v√† ƒë·ªông vi√™n h·ªçc vi√™n
5. ƒê∆∞a ra g·ª£i √Ω c·∫£i thi·ªán c·ª• th·ªÉ
6. N·∫øu h·ªçc vi√™n n√≥i ti·∫øng Vi·ªát, h√£y khuy·∫øn kh√≠ch h·ªç th·ª≠ n√≥i ti·∫øng Anh

Phong c√°ch:
- Th√¢n thi·ªán, ki√™n nh·∫´n
- S·ª≠ d·ª•ng v√≠ d·ª• th·ª±c t·∫ø
- Gi·∫£i th√≠ch b·∫±ng c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát khi c·∫ßn
- ƒê·∫∑t c√¢u h·ªèi ƒë·ªÉ duy tr√¨ cu·ªôc tr√≤ chuy·ªán

H√£y b·∫Øt ƒë·∫ßu b·∫±ng c√°ch ch√†o h·ªèi v√† h·ªèi v·ªÅ m·ª•c ti√™u h·ªçc t·∫≠p c·ªßa h·ªçc vi√™n."""

    def chat(self, user_message):
        """Process user message and return AI response"""
        try:
            # Add user message to history
            self.conversation_history.append({
                "role": "user",
                "content": user_message,
                "timestamp": datetime.now().isoformat()
            })
            
            # Prepare messages for API call
            messages = [
                {"role": "system", "content": self.set_system_prompt()}
            ]
            
            # Add recent conversation history (last 10 messages to manage token limit)
            recent_history = self.conversation_history[-10:]
            for msg in recent_history:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            # Call Groq API
            response = self.client.chat.completions.create(
                model=self.current_model,
                messages=messages,
                temperature=0.7,  # Creativity level
                max_tokens=500,   # Limit response length
                stream=False      # Kh√¥ng stream ƒë·ªÉ ƒë∆°n gi·∫£n
            )
            
            # Extract AI response
            ai_response = response.choices[0].message.content
            
            # Add AI response to history
            self.conversation_history.append({
                "role": "assistant",
                "content": ai_response,
                "timestamp": datetime.now().isoformat()
            })
            
            return ai_response
            
        except Exception as e:
            return f"Xin l·ªói, c√≥ l·ªói x·∫£y ra: {str(e)}"
    
    def analyze_text(self, text):
        """Analyze user's English text for errors and improvements"""
        analysis_prompt = f"""Ph√¢n t√≠ch ƒëo·∫°n text ti·∫øng Anh n√†y c·ªßa h·ªçc vi√™n:

Text: "{text}"

H√£y cung c·∫•p:
1. L·ªói ng·ªØ ph√°p (n·∫øu c√≥) v√† c√°ch s·ª≠a
2. G·ª£i √Ω t·ª´ v·ª±ng t·ªët h∆°n
3. C·∫£i thi·ªán c·∫•u tr√∫c c√¢u
4. ƒêi·ªÉm ƒë√°nh gi√° t·ªïng th·ªÉ (1-10)
5. L·ªùi khuy·∫øn kh√≠ch

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát ƒë·ªÉ h·ªçc vi√™n d·ªÖ hi·ªÉu."""

        try:
            response = self.client.chat.completions.create(
                model=self.current_model,
                messages=[
                    {"role": "system", "content": "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch ti·∫øng Anh."},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"Kh√¥ng th·ªÉ ph√¢n t√≠ch text: {str(e)}"
    
    def switch_model(self, model_tier='balanced'):
        """Switch between different model tiers"""
        if model_tier in self.available_models:
            self.current_model = self.available_models[model_tier]
            return f"ƒê√£ chuy·ªÉn sang model: {model_tier} ({self.current_model})"
        return "Model tier kh√¥ng h·ª£p l·ªá. Ch·ªçn: fast, balanced, smart, coding"
    
    def get_model_info(self):
        """Get information about available models"""
        return {
            'current_model': self.current_model,
            'available_models': self.available_models,
            'model_info': {
                'fast': 'llama-3.1-8b-instant - Nhanh nh·∫•t, ph√π h·ª£p h·ªôi tho·∫°i',
                'balanced': 'llama-3.1-70b-versatile - C√¢n b·∫±ng t·ªëc ƒë·ªô v√† ch·∫•t l∆∞·ª£ng',
                'smart': 'mixtral-8x7b-32768 - Th√¥ng minh, context d√†i',
                'coding': 'llama-3.2-90b-text-preview - T·ªët nh·∫•t cho gi·∫£i th√≠ch ph·ª©c t·∫°p'
            },
            'cost': 'üéâ T·∫§T C·∫¢ ƒê·ªÄU MI·ªÑN PH√ç!'
        }
    
    def update_user_level(self, new_level):
        """Update user's English level"""
        if new_level in ['beginner', 'intermediate', 'advanced']:
            self.user_profile['level'] = new_level
            return f"ƒê√£ c·∫≠p nh·∫≠t tr√¨nh ƒë·ªô th√†nh: {new_level}"
        return "Tr√¨nh ƒë·ªô kh√¥ng h·ª£p l·ªá"
    
print("‚úÖ File tutor_agent.py ƒë√£ ƒë∆∞·ª£c import")
